{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61458,"databundleVersionId":6632105,"sourceType":"competition"},{"sourceId":7046257,"sourceType":"datasetVersion","datasetId":4054690}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Authors:**\n#### - **Ben mouloud Abir**\n#### - **El Allali Fatima Zahrae**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T10:11:44.077932Z","iopub.execute_input":"2023-11-22T10:11:44.078869Z","iopub.status.idle":"2023-11-22T10:11:44.085049Z","shell.execute_reply.started":"2023-11-22T10:11:44.078835Z","shell.execute_reply":"2023-11-22T10:11:44.084115Z"}}},{"cell_type":"markdown","source":"## **Introduction:**","metadata":{}},{"cell_type":"markdown","source":"**This Pokémon classification project aims to deploy a deep learning model for accurately categorizing Pokémon species based on images. The dataset encompasses a variety of Pokémon images, and the primary task involves mapping these images to their respective Pokémon IDs. The project unfolds in several critical stages, each contributing to the successful implementation and training of the classification model.Our model gave these numbers with just 5 epochs:**\n\n- **Validation Accuracy: 0.9447**\n\n- **Number of Correct Predictions: 854**\n\n- **Number of Incorrect Predictions: 50**","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align:center;\">\n    <img src=\"https://anecdotes-de-jeux-video.fr/wp-content/uploads/2019/07/mignon-pokemon.jpg\" alt=\"pokemon\" style=\"width:80%;\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"## **Data: Load, display samples, perform data augmentation, and verify effectiveness**\n","metadata":{}},{"cell_type":"markdown","source":"- **In this section, we load the Pokémon dataset, perform necessary data transformations,and visualize a subset of samples. Data augmentation techniques are applied to enhance the model's ability to generalize.**","metadata":{}},{"cell_type":"code","source":"import os\nimport csv\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.optim.lr_scheduler import StepLR\nfrom torchvision.models.resnet import ResNet50_Weights\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n#from efficientnet_pytorch import EfficientNet\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport random\n\n\n# Chemins d'accès aux données\ncsv_path = \"/kaggle/input/polytech-nice-deep-learning-course-2023/polytech/pokemon_ids.csv\"\ndata_dir = \"/kaggle/input/polytech-nice-deep-learning-course-2023/polytech/trainval\"\n\n# Lire le CSV pour obtenir l'ordre correct des noms de Pokémon\ncorrect_order = []\nwith open(csv_path, 'r') as file:\n    reader = csv.reader(file)\n    next(reader)  # Ignorer la ligne d'en-tête\n    for line in reader:\n        if len(line) >= 2:\n            correct_order.append(line[1])\n\n# Créer une correspondance des noms de Pokémon aux IDs (en commençant à partir de 1)\nclass_to_id = {name: idx + 1 for idx, name in enumerate(correct_order)}","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:27:10.516507Z","iopub.execute_input":"2023-11-24T19:27:10.517291Z","iopub.status.idle":"2023-11-24T19:27:15.577361Z","shell.execute_reply.started":"2023-11-24T19:27:10.517252Z","shell.execute_reply":"2023-11-24T19:27:15.576391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**loading and preprocessing the Pokémon dataset**\n\nThe CSV file containing the correct order of Pokémon names is read, and a mapping from names to IDs is created. The custom PokemonDataset class is introduced, facilitating the loading of images and labels. Additionally, the dataset is split into training and validation sets, and data loaders are prepared for efficient model training.","metadata":{}},{"cell_type":"code","source":"# Lire le CSV pour obtenir l'ordre correct des noms de Pokémon\ncorrect_order = []\nwith open(csv_path, 'r') as file:\n    reader = csv.reader(file)\n    next(reader)  # Ignorer la ligne d'en-tête\n    for line in reader:\n        if len(line) >= 2:\n            correct_order.append(line[1])\n\n# Créer une correspondance des noms de Pokémon aux IDs (en commençant à partir de 1)\nclass_to_id = {name: idx + 1 for idx, name in enumerate(correct_order)}\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:27:21.142328Z","iopub.execute_input":"2023-11-24T19:27:21.142871Z","iopub.status.idle":"2023-11-24T19:27:21.150454Z","shell.execute_reply.started":"2023-11-24T19:27:21.142836Z","shell.execute_reply":"2023-11-24T19:27:21.149322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformation pour la prétraitement des images\n#data_transform = transforms.Compose([\n    #transforms.Resize((224, 224)),\n    #transforms.ToTensor(),\n#])\n# Transformation pour la prétraitement des images\n#data_transform = transforms.Compose([\n    #transforms.Resize((224, 224)),# Resize the image to fit most pre-trained models.\n    #transforms.RandomHorizontalFlip(),\n    #transforms.RandomRotation(10),\n    #transforms.ToTensor(),\n    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])# ImageNet stats\n#])\ndata_transform = transforms.Compose([transforms.Resize((224, 224)),#ça marche mieux peut parcequ'il y a des details dans nos images qui sont plus détécter avec une dimension plus grande\n                                 #transforms.RandomHorizontalFlip(),\n                                 #transforms.RandomRotation(15),\n                                 transforms.RandomRotation(degrees=30),  # Try different rotation angles\n                                 transforms.RandomHorizontalFlip(p=0.5),  # Adjust flip probability\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                                 #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Validation Accuracy: 0.9646 avec le loss qui diminue\n                                    ])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:27:30.410335Z","iopub.execute_input":"2023-11-24T19:27:30.410666Z","iopub.status.idle":"2023-11-24T19:27:30.417365Z","shell.execute_reply.started":"2023-11-24T19:27:30.410640Z","shell.execute_reply":"2023-11-24T19:27:30.416010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classe de jeu de données personnalisée\nclass PokemonDataset(Dataset):\n    def __init__(self, data_dir, class_to_id, transform=None):\n        self.data_dir = data_dir\n        self.class_to_id = class_to_id\n        self.transform = transform\n\n        self.images = []\n        self.labels = []\n\n        self.load_data()\n\n    def load_data(self):\n        for class_name in os.listdir(self.data_dir):\n            if class_name in self.class_to_id:\n                class_id = self.class_to_id[class_name]\n                class_path = os.path.join(self.data_dir, class_name)\n\n                for image_name in os.listdir(class_path):\n                    image_path = os.path.join(class_path, image_name)\n                    self.images.append(image_path)\n                    self.labels.append((class_id, class_name))\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_path, (class_id, class_name) = self.images[idx], self.labels[idx]\n\n        # Charger l'image et appliquer la transformation\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_id, class_name\n    \n# Instance de PokemonDataset\npokemon_dataset = PokemonDataset(data_dir, class_to_id, transform=data_transform)\n\n# Division des données en ensembles d'entraînement et de validation\ntrain_size = int(0.85 * len(pokemon_dataset))\nval_size = len(pokemon_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(pokemon_dataset, [train_size, val_size])\n\n# DataLoaders pour l'entraînement et la validation\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:27:33.673055Z","iopub.execute_input":"2023-11-24T19:27:33.673790Z","iopub.status.idle":"2023-11-24T19:27:35.503240Z","shell.execute_reply.started":"2023-11-24T19:27:33.673746Z","shell.execute_reply":"2023-11-24T19:27:35.502451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose a random subset of images for visualization\nsample_images = random.sample(pokemon_dataset.images, 5)\n\n# Display sample images with their corresponding class names\nfig, axes = plt.subplots(1, 5, figsize=(15, 3))\nfor i, image_path in enumerate(sample_images):\n    image = Image.open(image_path).convert(\"RGB\")\n    class_name = os.path.basename(os.path.dirname(image_path))\n    axes[i].imshow(image)\n    axes[i].set_title(f\"Class: {class_name}\")\n    axes[i].axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:27:51.472611Z","iopub.execute_input":"2023-11-24T19:27:51.473460Z","iopub.status.idle":"2023-11-24T19:27:52.037201Z","shell.execute_reply.started":"2023-11-24T19:27:51.473424Z","shell.execute_reply":"2023-11-24T19:27:52.036364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Network: Assemble a deep learning network while justifying technical choices**","metadata":{}},{"cell_type":"markdown","source":"**Here, we use a pre-trained ResNet101 model as our base architecture. We modify the fully connected layer to adapt it for our classification task. The model is moved to the GPU if available. We also define the loss function, optimizer, and a learning rate scheduler to facilitate model training.**","metadata":{}},{"cell_type":"code","source":"# Modèle ResNet18 pré-entraîné\n#resnet_model = models.resnet18(pretrained=True)\n#resnet_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\nresnet_model = models.resnet101(pretrained=True)\n#resnet_model = models.resnet34(pretrained=True)\n\nnum_features = resnet_model.fc.in_features\n\n# Modifier la dernière couche entièrement connectée pour le nombre de classes\nnum_classes = len(class_to_id) + 1  # Ajouter 1 si les identifiants de classe commencent à partir de 1\nresnet_model.fc = nn.Linear(num_features, num_classes)\n\n# Déplacer le modèle sur le GPU si disponible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet_model.to(device)\n\n# Fonction de perte et optimiseur\ncriterion = nn.CrossEntropyLoss()\n\n#optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\noptimizer = optim.SGD(resnet_model.parameters(), lr=0.01, momentum=0.9)\n\n# Learning Rate Scheduler\n#scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, threshold=0.9, factor=0.1, verbose=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:28:02.439011Z","iopub.execute_input":"2023-11-24T19:28:02.439338Z","iopub.status.idle":"2023-11-24T19:28:07.621721Z","shell.execute_reply.started":"2023-11-24T19:28:02.439313Z","shell.execute_reply":"2023-11-24T19:28:07.620821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training: Train the network on training data**\n","metadata":{}},{"cell_type":"markdown","source":"**This section includes the training loop where we iterate through multiple epochs to optimize the model parameters. The training process involves calculating the loss, backpropagating the gradients, and updating the model's weights. Training statistics such as loss and accuracy are recorded for analysis.**","metadata":{}},{"cell_type":"code","source":"# Lists to store loss and accuracy values during training\ntrain_losses = []\ntrain_accuracies = []\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    resnet_model.train()\n    running_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n\n    for inputs, class_ids, _ in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n        inputs, class_ids = inputs.to(device), class_ids.to(device)\n        optimizer.zero_grad()\n        outputs = resnet_model(inputs)\n        loss = criterion(outputs, class_ids)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_samples += class_ids.size(0)\n        correct_predictions += (predicted == class_ids).sum().item()\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_accuracy = correct_predictions / total_samples\n\n    train_losses.append(epoch_loss)\n    train_accuracies.append(epoch_accuracy)\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:28:15.452601Z","iopub.execute_input":"2023-11-24T19:28:15.453304Z","iopub.status.idle":"2023-11-24T19:36:12.612691Z","shell.execute_reply.started":"2023-11-24T19:28:15.453265Z","shell.execute_reply":"2023-11-24T19:36:12.611668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Experiments: Testing, display confusion matrix, display some test results**","metadata":{}},{"cell_type":"markdown","source":"**In the experiments section, we evaluate the trained model on the validation set. We compute metrics such as accuracy and create a confusion matrix for a more in-depth analysis. Additionally, we visualize a subset of incorrectly classified test images. In the experiments section, we evaluate the trained model on the validation set. We compute metrics such as accuracy and create a confusion matrix for a more in-depth analysis. Additionally, we visualize a subset of incorrectly classified test images.**","metadata":{}},{"cell_type":"code","source":"# Validation loop\nresnet_model.eval()\nval_corrects = 0\nval_total = 0\nincorrect_predictions = []\nval_losses = []\nval_accuracies = []\n# Initialize lists to store predicted and true labels for the entire validation set\nval_predictions = []  #Predicted labels stored in a list\nval_true_labels = [] #True labels stored in a list\n\nval_running_loss = 0.0\n\nwith torch.no_grad():\n    for inputs, class_ids, _ in tqdm(val_loader, desc=\"Evaluating on Validation Set\"):\n        inputs, class_ids = inputs.to(device), class_ids.to(device)\n        outputs = resnet_model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        val_total += class_ids.size(0)\n        val_corrects += (predicted == class_ids).sum().item()\n        val_predictions.extend(predicted.cpu().numpy())\n        val_true_labels.extend(class_ids.cpu().numpy())\n\n        # Collect incorrect predictions for further analysis\n        incorrect_mask = predicted != class_ids\n        incorrect_predictions.extend([(image, true_label, predicted_label)\n                                      for image, true_label, predicted_label in zip(inputs[incorrect_mask], class_ids[incorrect_mask], predicted[incorrect_mask])])\n\n\n\n    # Calculate validation accuracy\n        val_accuracy = val_corrects / val_total\n        val_losses.append(val_running_loss / len(val_loader))\n        val_accuracies.append(val_accuracy)\n\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n    print(f\"Number of Correct Predictions: {val_corrects}\")\n    print(f\"Number of Incorrect Predictions: {val_total - val_corrects}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:43:19.322479Z","iopub.execute_input":"2023-11-24T21:43:19.323447Z","iopub.status.idle":"2023-11-24T21:43:19.722320Z","shell.execute_reply.started":"2023-11-24T21:43:19.323409Z","shell.execute_reply":"2023-11-24T21:43:19.720830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation accuracy curves\nplt.figure(figsize=(10, 5))\nplt.plot(train_accuracies, label='Training Accuracy', marker='o')\nplt.plot(val_accuracies, label='Validation Accuracy', marker='o')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy Curves')\nplt.legend()\nplt.show()\n\n# Plotting the training and validation loss curves\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Training Loss', marker='o')\nplt.plot(val_losses, label='Validation Loss', marker='o')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss Curves')\nplt.legend()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:52:23.805779Z","iopub.execute_input":"2023-11-24T19:52:23.806221Z","iopub.status.idle":"2023-11-24T19:52:24.403760Z","shell.execute_reply.started":"2023-11-24T19:52:23.806185Z","shell.execute_reply":"2023-11-24T19:52:24.402812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Visualize a subset of images with incorrect predictions","metadata":{}},{"cell_type":"code","source":"# Visualize a subset of images with incorrect predictions\nnum_images_to_visualize = 10\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\nfig.suptitle('Incorrect Predictions', fontsize=16)\n\nfor i, (image, true_label, predicted_label) in enumerate(incorrect_predictions[:num_images_to_visualize]):\n    # Convert the image from Tensor to NumPy array\n    image_np = image.permute(1, 2, 0).cpu().numpy()\n\n    # Ensure the labels are within the correct range\n    true_label = min(true_label, len(correct_order) - 1)\n    predicted_label = min(predicted_label, len(correct_order) - 1)\n    \n\n    row, col = divmod(i, 5)\n    \n    # Print the true and predicted labels with indices\n    print(f\"Index {i}: True Label: {true_label} ({correct_order[true_label]}), Predicted Label: {predicted_label} ({correct_order[predicted_label]})\")\n   \n    axes[row, col].imshow(image_np)\n    axes[row, col].set_title(f\"True: {correct_order[true_label]}\\nPredicted: {correct_order[predicted_label]}\", fontsize=8)\n    axes[row, col].axis('off')\n\n\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:53:04.160307Z","iopub.execute_input":"2023-11-24T19:53:04.160972Z","iopub.status.idle":"2023-11-24T19:53:05.561597Z","shell.execute_reply.started":"2023-11-24T19:53:04.160937Z","shell.execute_reply":"2023-11-24T19:53:05.560547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the confusion matrix\nconf_matrix = confusion_matrix(val_true_labels, val_predictions)\n\n# Display the confusion matrix as a heatmap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=False, fmt='d', cmap='Reds', cbar=True)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:38:42.866310Z","iopub.execute_input":"2023-11-24T21:38:42.866733Z","iopub.status.idle":"2023-11-24T21:38:43.863899Z","shell.execute_reply.started":"2023-11-24T21:38:42.866700Z","shell.execute_reply":"2023-11-24T21:38:43.862928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Evaluation on Test Set and Submission**","metadata":{}},{"cell_type":"markdown","source":"**The final part involves creating a custom dataset for the test set, evaluating the trained model on this test set, and generating a submission CSV file. Predictions are made for the Pokémon IDs, and the results are saved in a DataFrame. The DataFrame is then exported to a CSV file for submission.**","metadata":{}},{"cell_type":"code","source":"# Create a custom dataset class for the test set\nclass TestPokemonDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.images = [os.path.join(data_dir, img) for img in os.listdir(data_dir)]\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_path = self.images[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, os.path.basename(image_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:08:39.706988Z","iopub.execute_input":"2023-11-24T20:08:39.707404Z","iopub.status.idle":"2023-11-24T20:08:39.714647Z","shell.execute_reply.started":"2023-11-24T20:08:39.707371Z","shell.execute_reply":"2023-11-24T20:08:39.713749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestPokemonDataset(\"/kaggle/input/polytech-nice-deep-learning-course-2023/polytech/test\", transform=data_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:08:43.563088Z","iopub.execute_input":"2023-11-24T20:08:43.563463Z","iopub.status.idle":"2023-11-24T20:08:43.797562Z","shell.execute_reply.started":"2023-11-24T20:08:43.563434Z","shell.execute_reply":"2023-11-24T20:08:43.796737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize 5 random images from the test dataset\nnum_images_to_visualize = 3\n\n# Get the total number of images in the test dataset\nnum_images_in_test = len(test_dataset)\nprint(f\"Number of images in the test dataset: {num_images_in_test}\")\n\n# Get 5 random indices\nrandom_indices = random.sample(range(num_images_in_test), num_images_to_visualize)\n\n# Create a DataLoader for the selected images\nselected_test_loader = DataLoader(\n    dataset=torch.utils.data.Subset(test_dataset, random_indices),\n    batch_size=num_images_to_visualize,\n    shuffle=False\n)\n\n# Display information about the selected test images\nimages_to_display = []\nfor test_inputs, filenames in tqdm(selected_test_loader, desc=\"Visualizing Test Images\"):\n    # Display information about each image\n    for i in range(num_images_to_visualize):\n        image = test_inputs[i].numpy().transpose((1, 2, 0))\n        filename = filenames[i]\n        image_size = test_inputs[i].shape\n\n        images_to_display.append((image, filename, image_size))\n\n# Plot the selected test images side by side\nfig, axes = plt.subplots(1, num_images_to_visualize, figsize=(15, 3))\n\nfor i, (image, filename, image_size) in enumerate(images_to_display):\n    axes[i].imshow(image)\n    axes[i].set_title(f\"Filename: {filename}\\nImage Size: {image_size}\")\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:08:57.942139Z","iopub.execute_input":"2023-11-24T20:08:57.942782Z","iopub.status.idle":"2023-11-24T20:08:58.378224Z","shell.execute_reply.started":"2023-11-24T20:08:57.942738Z","shell.execute_reply":"2023-11-24T20:08:58.377270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test dataset and create a submission CSV\nresnet_model.eval()\npredictions = []\n\nwith torch.no_grad():\n    for test_inputs, filenames in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n        test_inputs = test_inputs.to(device)\n        test_outputs = resnet_model(test_inputs)\n        _, test_predicted = torch.max(test_outputs, 1)\n        predictions.extend(zip(filenames, test_predicted.cpu().numpy()))\n\n# Create a DataFrame and save it as a CSV\nsubmission_df = pd.DataFrame(predictions, columns=[\"filename\", \"pokemon_id\"])\nsubmission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:09:11.471856Z","iopub.execute_input":"2023-11-24T20:09:11.472218Z","iopub.status.idle":"2023-11-24T20:09:20.918903Z","shell.execute_reply.started":"2023-11-24T20:09:11.472188Z","shell.execute_reply":"2023-11-24T20:09:20.917946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:09:25.989218Z","iopub.execute_input":"2023-11-24T20:09:25.989631Z","iopub.status.idle":"2023-11-24T20:09:26.004704Z","shell.execute_reply.started":"2023-11-24T20:09:25.989598Z","shell.execute_reply":"2023-11-24T20:09:26.003607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Bonus: BENCHMARKING**","metadata":{}},{"cell_type":"markdown","source":"**In this section, we'll explore the evaluation and performance assessment of our trained neural network model on an embedded device. The primary objective is to evaluate the neural network's performance, particularly its efficiency and accuracy, when deployed on an embedded device.**","metadata":{}},{"cell_type":"code","source":"resnet_model.to('cpu') \n# Input to the model - adjust according to your input size\nsample_input = torch.randn(1, 3, 224, 224).to('cpu')  # Assuming device is 'cuda' for GPU\n\n# Export the model to ONNX\ntorch.onnx.export(\n    resnet_model,                    # PyTorch model\n    sample_input,                    # Sample input tensor\n    \"resnet_model.onnx\",             # Filepath to save the ONNX file\n    export_params=True,               # Export model parameters\n    opset_version=11,                # ONNX opset version\n    do_constant_folding=True,        # Optimize constant folding\n    input_names=[\"input\"],           # Input names within the model\n    output_names=[\"output\"],         # Output names within the model\n    dynamic_axes={                   # Dynamic axes for variable length inputs/outputs\n        \"input\": {0: \"batch_size\"},  # Variable length axes \n    \n        \"output\": {0: \"batch_size\"}  # Variable length axes\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T16:50:07.827898Z","iopub.execute_input":"2023-11-24T16:50:07.828310Z","iopub.status.idle":"2023-11-24T16:50:12.032614Z","shell.execute_reply.started":"2023-11-24T16:50:07.828282Z","shell.execute_reply":"2023-11-24T16:50:12.031621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(\"/kaggle/input/benchmarking/Cpu1.png\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:53.270896Z","iopub.execute_input":"2023-11-24T21:25:53.271661Z","iopub.status.idle":"2023-11-24T21:25:53.282465Z","shell.execute_reply.started":"2023-11-24T21:25:53.271626Z","shell.execute_reply":"2023-11-24T21:25:53.281520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Progress: Describe progress and improvements**","metadata":{}},{"cell_type":"markdown","source":"**This part includes a textual description of the progress made during the training and experimentation phases. It outlines the impact of various technical choices on model accuracy and efficiency.**","metadata":{}},{"cell_type":"markdown","source":"**Initial Model (Version 1):**\n\n- Utilized ResNet18 with basic data augmentation (resizing, converting to tensor).\n\n- Optimizer: Adam with a learning rate of 0.001.\n\n- Achieved Validation Accuracy: 0.8473.\n\n- Identified 1021 Correct Predictions and 184 Incorrect Predictions.\n\n**Version 2:**\n\n- Introduced a learning rate scheduler (StepLR).\n\n- Improved Validation Accuracy to 0.8896.\n\n- Enhanced Correct Predictions to 1072 while reducing Incorrect Predictions to 133.\n\n**Version 3:**\n\n- Expanded data augmentation techniques (rotation, larger image dimensions).\n\n- Adjusted the learning rate to 0.01.\n\n- Significantly increased Validation Accuracy to 0.9386.\n\n- Improved Correct Predictions to 1131 and reduced Incorrect Predictions to 74.\n\n**Model Variations:**\n\n- Explored different pretrained models: ResNet18, ResNet34, ResNet50, and ResNet101.\n\n- Noted improvement in accuracy with ResNet50 but a decrease with ResNet34, and increased more with ResNet101. But the training speed is faster with ResNet18, which is normal since a model like ResNet101 contains more layers and is more complex.\n\n**Final Version:**\n\n- Switched to SGD optimizer with momentum (lr=0.03, momentum=0.9).\n\n- Employed a learning rate scheduler (ReduceLROnPlateau).\n\n- Achieved significant improvement in accuracy.\n\n- Reached an accuracy of 0.95 with 5 epochs and further increased to 0.97 with 15 epochs.\n\n**Observations and Learnings:**\n\nData augmentation significantly impacted performance, especially with increased variations.\n\nHigher learning rates (e.g., 0.01) were more effective, likely due to dataset size and limited iterations.\n\nModel choice affected both training time and accuracy, with ResNet101 showing better performance.\n\nOptimizer and learning rate scheduler adjustments notably improved final accuracy.\nThis progressive enhancement involved a systematic exploration of data augmentation, model variations, optimizer choices, and learning rate adjustments, leading to substantial accuracy gains. The final model's accuracy reached a commendable 97% after iterative improvements and fine-tuning of hyperparameters.","metadata":{}},{"cell_type":"markdown","source":"## Explanation of Found Results\n\n**ResNet18:** A pre-trained convolutional neural network model developed by Microsoft. It consists of 18 layers.\n\n**Pretrained Model:** A pre-trained model is a network already trained on a large amount of data, often on images from a database like ImageNet. It's used as a starting point for transfer learning tasks.\n\n- #### **Model Versions (ResNet):**\n\nResNet34, ResNet50, ResNet101: These are variants of ResNet with deeper architectures. The number after \"ResNet\" indicates the number of layers in the network. For example, ResNet50 has 50 layers, and ResNet101 has 101. The main difference lies in the depth of the network and its ability to capture complex features more accurately as the depth increases.\n\n- #### **Optimizers:**\n\n**Adam Optimizer:** A popular optimization algorithm used to update the model's weights based on gradients calculated from training data. It adapts the learning rate for each individual parameter.\n\n**SGD Optimizer (Stochastic Gradient Descent):** Another optimization algorithm that updates weights by moving in the opposite direction of the calculated gradient. The momentum (0.9 in this case) maintains some inertia in updates to avoid local minima.\n\n**Difference between Optimizers:**\n\n**Adam:** It adjusts the learning rate for each parameter, which can be beneficial at the beginning of training when gradients vary significantly. However, this might lead to slower convergence with larger datasets.\n\n**SGD with Momentum:** Unlike Adam, it maintains a constant speed in updates, which might be more stable for large datasets, potentially enabling faster convergence.\n\n- #### **Scheduler:**\n\n**Scheduler (ReduceLROnPlateau):** A scheduler that dynamically adjusts the learning rate based on the model's performance on validation data. When accuracy stagnates or decreases, it reduces the learning rate to explore parameter space more finely.\n\n**Impact of the Scheduler:**\n\nThe scheduler adjusts the learning rate based on the model's actual performance on validation data. This can prevent overfitting and help the model converge towards more precise optima.\n\n\n- In this context, the scheduler likely regulated the model's learning speed, enabling more efficient convergence towards more accurate optima and potentially avoiding overfitting. The performance difference between optimizers (Adam and SGD) can be attributed to the convergence characteristics of these algorithms on different datasets, as well as their adaptability to specific model and dataset hyperparameters.\n","metadata":{}},{"cell_type":"markdown","source":"### **Conclusion: Provide concluding remarks and suggest future directions**","metadata":{}},{"cell_type":"markdown","source":"In the pursuit of improving the performance and capabilities of our Pokémon classification model, we can use several techniques:\n\n- **Fine-Tuning**:Fine-tuning helps the model adapt its learned features to the specific characteristics of the new task.In our case , we tried to use it but it reduced the accuracy and the convergence time.To troubleshoot and improve the situation we can:\n\n * Experiment with different hyperparameter settings.\n * Ensure that the dataset for fine-tuning is representative and diverse.\n * Consider monitoring metrics other than accuracy.\n * Try different fine-tuning strategies, such as adjusting the number of layers to fine-tune or    using different learning rates for different layers.\n\n- **Attention Mechanisms**: Integrate attention mechanisms such as SE blocks or self-attention to enhance the model's ability to focus on crucial parts of the images.\n\n\n- **Robustness and Adversarial Defense**: Strengthen the model's robustness against adversarial attacks by employing adversarial training techniques or augmenting data to include adversarial examples.\n\n\n- **Hyperparameter Optimization Strategies**: Experiment with advanced optimization methods for more effective hyperparameter tuning.\n\n\n- **Hardware Optimization for Embedded Devices**: Further optimize the model for deployment on resource-constrained devices through quantization and model pruning.\n\n- **Use Test Time Augmentation (TTA)**: It's a technique employed in machine learning and computer vision to enhance the performance of a trained model during the testing stage. This method involves applying various data augmentation transformations, such as rotations and flips, to a test image and obtaining predictions from the model for each augmented version. The final prediction is often derived by aggregating or averaging the predictions from all augmented versions. TTA aims to improve model robustness and reliability, particularly in scenarios with limited training data or when the model needs to generalize effectively to variations not present in the training set. \n","metadata":{}}]}